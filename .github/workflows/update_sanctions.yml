name: Update Sanctions List

on:
  schedule:
    - cron: '0 3 * * *'   # runs daily at 03:00 UTC
  workflow_dispatch:        # allow manual trigger from GitHub UI

jobs:
  update:
    runs-on: ubuntu-latest
    permissions:
      contents: write

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Fetch & parse sanctions (OpenSanctions + OFAC direct)
        run: |
          python3 - << 'PYEOF'
          import urllib.request, csv, json, re, io, xml.etree.ElementTree as ET
          from datetime import datetime, timezone
          from collections import Counter

          entries = {}

          def add(imo, name, lst, program=""):
              imo = re.sub(r'\D', '', str(imo))
              if len(imo) != 7:
                  return
              if imo not in entries:
                  entries[imo] = {"imo": imo, "name": name, "lists": [], "program": program}
              if lst not in entries[imo]["lists"]:
                  entries[imo]["lists"].append(lst)

          # Dataset prefix -> friendly label (substring match, order matters)
          DATASET_MAP = [
              ("us_ofac",    "OFAC"),
              ("eu_",        "EU"),
              ("gb_",        "UK"),
              ("un_",        "UN"),
              ("au_",        "Australia"),
              ("ca_",        "Canada"),
              ("ch_",        "Switzerland"),
              ("jp_",        "Japan"),
              ("ua_",        "Ukraine"),
              ("ru_",        "Russia"),
          ]

          def datasets_to_lists(datasets_str):
              matched = set()
              result = []
              for ds in datasets_str.split(";"):
                  ds = ds.strip().lower()
                  for prefix, label in DATASET_MAP:
                      if ds.startswith(prefix) and label not in matched:
                          result.append(label)
                          matched.add(label)
                          break
              return result or ["Sanctions"]

          # SOURCE 1: OpenSanctions consolidated CSV
          print("Fetching OpenSanctions CSV...", flush=True)
          try:
              req = urllib.request.Request(
                  "https://data.opensanctions.org/datasets/latest/sanctions/targets.simple.csv",
                  headers={"User-Agent": "VesselTracker-GH-Action/1.0"}
              )
              with urllib.request.urlopen(req, timeout=120) as r:
                  raw = r.read().decode("utf-8")

              reader = csv.DictReader(io.StringIO(raw))
              # Print headers for debugging
              fieldnames = reader.fieldnames or []
              print(f"  CSV columns: {fieldnames}", flush=True)

              os_count = 0
              for row in reader:
                  schema = row.get("schema", "")
                  if not any(s in schema.lower() for s in ("vessel", "ship")):
                      continue

                  # IMO is in 'identifiers' column e.g. "imo:1234567;mmsi:123456789"
                  imo_val = ""
                  identifiers = row.get("identifiers", "") or ""
                  m = re.search(r'imo:(\d{7})', identifiers, re.I)
                  if m:
                      imo_val = m.group(1)
                  if not imo_val:
                      for part in re.split(r'[;,\s]+', identifiers):
                          digits = re.sub(r'\D', '', part)
                          if len(digits) == 7:
                              imo_val = digits
                              break
                  if not imo_val:
                      for col in ("name", "sanctions", "aliases"):
                          m2 = re.search(r'\b(\d{7})\b', row.get(col, "") or "")
                          if m2:
                              imo_val = m2.group(1)
                              break
                  if not imo_val:
                      continue

                  name = (row.get("name") or "").split(";")[0].strip()
                  # 'dataset' column e.g. "us_ofac_sdn" or "eu_fsf;gb_hmt"
                  lists = datasets_to_lists(row.get("dataset", ""))
                  for lst in lists:
                      add(imo_val, name, lst)
                  os_count += 1

              print(f"  Vessel rows processed: {os_count} -> {len(entries)} unique IMOs", flush=True)

          except Exception as ex:
              print(f"  OpenSanctions failed: {ex}", flush=True)

          # SOURCE 2: OFAC SDN XML (direct, authoritative)
          print("Fetching OFAC SDN XML...", flush=True)
          before = len(entries)
          try:
              req = urllib.request.Request(
                  "https://www.treasury.gov/ofac/downloads/sdn.xml",
                  headers={"User-Agent": "Mozilla/5.0"}
              )
              with urllib.request.urlopen(req, timeout=90) as r:
                  tree = ET.parse(r)
              root = tree.getroot()
              sdn_entries = root.findall(".//{*}sdnEntry") or root.findall(".//sdnEntry")
              for e in sdn_entries:
                  stype = (e.findtext("{*}sdnType") or e.findtext("sdnType") or "").strip()
                  if stype not in ("Vessel", "Entity"):
                      continue
                  name = (e.findtext("{*}lastName") or e.findtext("lastName") or "").strip()
                  prog = next((p.text for p in e.iter() if p.tag.endswith("program") and p.text), "SDN")
                  for id_el in e.iter():
                      if not id_el.tag.endswith("id"):
                          continue
                      id_type, id_num = "", ""
                      for child in id_el:
                          tag = child.tag.split("}")[-1]
                          if tag == "idType":     id_type = (child.text or "").lower()
                          elif tag == "idNumber": id_num  = child.text or ""
                      if "imo" in id_type or "vessel" in id_type:
                          add(id_num, name, "OFAC", prog)
              print(f"  OFAC direct: +{len(entries)-before} additional IMOs", flush=True)
          except Exception as ex:
              print(f"  OFAC direct failed: {ex}", flush=True)

          # Write output
          import os
          os.makedirs("data", exist_ok=True)
          output = {
              "updated": datetime.now(timezone.utc).isoformat(),
              "total": len(entries),
              "sources": ["OpenSanctions consolidated (OFAC, EU, UK, UN, AU, CA, CH, JP, UA)", "OFAC SDN direct"],
              "entries": sorted(entries.values(), key=lambda x: x["imo"])
          }
          with open("data/sanctioned_imos.json", "w") as f:
              json.dump(output, f, separators=(",", ":"))

          counter = Counter()
          for e in entries.values():
              for l in e["lists"]:
                  counter[l] += 1
          print(f"\n=== DONE: {len(entries)} total unique sanctioned vessel IMOs ===")
          for lst, count in counter.most_common():
              print(f"   {lst}: {count}")
          PYEOF

      - name: Commit updated sanctions data
        run: |
          git config user.name  "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add data/sanctioned_imos.json
          git diff --cached --quiet && echo "No changes" || git commit -m "chore: update sanctioned_imos.json [$(date -u +%Y-%m-%d)]"
          git push
