name: Update Sanctions List

on:
  schedule:
    - cron: '0 3 * * *'   # runs daily at 03:00 UTC
  workflow_dispatch:        # allow manual trigger from GitHub UI

jobs:
  update:
    runs-on: ubuntu-latest
    permissions:
      contents: write

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Fetch & parse sanctions (all sources via OpenSanctions + OFAC direct)
        run: |
          python3 - << 'PYEOF'
          import urllib.request, csv, json, re, io, xml.etree.ElementTree as ET
          from datetime import datetime, timezone

          entries = {}  # imo -> {imo, name, lists, program}

          def add(imo, name, lst, program=""):
              imo = re.sub(r'\D', '', str(imo))
              if len(imo) != 7:
                  return
              if imo not in entries:
                  entries[imo] = {"imo": imo, "name": name, "lists": [], "program": program}
              if lst not in entries[imo]["lists"]:
                  entries[imo]["lists"].append(lst)

          # SOURCE 1: OpenSanctions consolidated CSV
          # Free for non-commercial use. Covers: OFAC, EU (all Russia packages),
          # UK OFSI, UN 1718 (North Korea), Australia, Canada, Switzerland, Japan, Ukraine, 80+ more.
          # https://www.opensanctions.org/datasets/sanctions/
          print("Fetching OpenSanctions consolidated CSV...", flush=True)
          try:
              req = urllib.request.Request(
                  "https://data.opensanctions.org/datasets/latest/sanctions/targets.simple.csv",
                  headers={"User-Agent": "VesselTracker-GH-Action/1.0"}
              )
              with urllib.request.urlopen(req, timeout=120) as r:
                  raw = r.read().decode("utf-8")

              reader = csv.DictReader(io.StringIO(raw))
              os_count = 0
              for row in reader:
                  schema = row.get("schema", "")
                  if schema not in ("Vessel", "Ship"):
                      continue
                  imo_val = ""
                  for col in ("imoNumber", "registrationNumber", "id"):
                      val = row.get(col, "")
                      for part in val.split(";"):
                          part = re.sub(r'\D', '', part.strip())
                          if len(part) == 7:
                              imo_val = part
                              break
                      if imo_val:
                          break
                  if not imo_val:
                      for col, val in row.items():
                          m = re.search(r'\b(\d{7})\b', val or "")
                          if m:
                              imo_val = m.group(1)
                              break
                  if not imo_val:
                      continue
                  name = row.get("name", "") or row.get("caption", "")
                  datasets = row.get("datasets", "")
                  mapping = {
                      "us_ofac": "OFAC", "eu_fsf": "EU", "eu_": "EU",
                      "gb_hmt": "UK", "un_": "UN", "au_dfat": "Australia",
                      "ca_sema": "Canada", "ch_seco": "Switzerland",
                      "jp_meti": "Japan", "ua_sfms": "Ukraine",
                  }
                  matched = set()
                  list_names = []
                  for ds in datasets.split(";"):
                      ds = ds.strip()
                      for prefix, label in mapping.items():
                          if ds.startswith(prefix) and label not in matched:
                              list_names.append(label)
                              matched.add(label)
                              break
                  if not list_names:
                      list_names = ["Sanctions"]
                  for lst in list_names:
                      add(imo_val, name, lst)
                  os_count += 1

              print(f"  OpenSanctions: {os_count} vessel rows -> {len(entries)} unique IMOs", flush=True)

          except Exception as ex:
              print(f"  OpenSanctions failed: {ex}", flush=True)

          # SOURCE 2: OFAC SDN XML direct (authoritative fallback)
          print("Fetching OFAC SDN XML (authoritative)...", flush=True)
          before = len(entries)
          try:
              req = urllib.request.Request(
                  "https://www.treasury.gov/ofac/downloads/sdn.xml",
                  headers={"User-Agent": "Mozilla/5.0"}
              )
              with urllib.request.urlopen(req, timeout=90) as r:
                  tree = ET.parse(r)
              root = tree.getroot()
              sdn_entries = root.findall(".//{*}sdnEntry") or root.findall(".//sdnEntry")
              for e in sdn_entries:
                  stype = (e.findtext("{*}sdnType") or e.findtext("sdnType") or "").strip()
                  if stype not in ("Vessel", "Entity"):
                      continue
                  name = (e.findtext("{*}lastName") or e.findtext("lastName") or "").strip()
                  prog = next((p.text for p in e.iter() if p.tag.endswith("program") and p.text), "SDN")
                  for id_el in e.iter():
                      if not id_el.tag.endswith("id"):
                          continue
                      id_type, id_num = "", ""
                      for child in id_el:
                          tag = child.tag.split("}")[-1]
                          if tag == "idType":    id_type = (child.text or "").lower()
                          elif tag == "idNumber": id_num  = child.text or ""
                      if "imo" in id_type or "vessel" in id_type:
                          add(id_num, name, "OFAC", prog)
              print(f"  OFAC direct: +{len(entries)-before} additional IMOs", flush=True)
          except Exception as ex:
              print(f"  OFAC direct failed: {ex}", flush=True)

          # Write output
          import os
          os.makedirs("data", exist_ok=True)
          output = {
              "updated": datetime.now(timezone.utc).isoformat(),
              "total": len(entries),
              "sources": ["OpenSanctions (OFAC, EU all packages, UK, UN 1718, AU, CA, CH, JP, UA, 80+ lists)", "OFAC SDN direct"],
              "entries": sorted(entries.values(), key=lambda x: x["imo"])
          }
          with open("data/sanctioned_imos.json", "w") as f:
              json.dump(output, f, separators=(",", ":"))

          from collections import Counter
          counter = Counter()
          for e in entries.values():
              for l in e["lists"]:
                  counter[l] += 1
          print(f"\n=== DONE: {len(entries)} total unique sanctioned vessel IMOs ===")
          for lst, count in counter.most_common():
              print(f"   {lst}: {count}")
          PYEOF

      - name: Commit updated sanctions data
        run: |
          git config user.name  "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add data/sanctioned_imos.json
          git diff --cached --quiet && echo "No changes" || git commit -m "chore: update sanctioned_imos.json [$(date -u +%Y-%m-%d)]"
          git push
